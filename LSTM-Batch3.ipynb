{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import RegexpTokenizer as regextoken\n",
    "\n",
    "# #LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('D:/INSOFE Internship/CUTE4/train')\n",
    "\n",
    "data = pd.read_csv(\"train.csv\",header=0)\n",
    "test = pd.read_csv(\"test.csv\",header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #UNDERSTAND THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'converse'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape \n",
    "\n",
    "test.shape \n",
    "\n",
    "data.columns\n",
    "\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # DISPLAY THE INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=11455, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index\n",
    "\n",
    "test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Understand the distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>categories</th>\n",
       "      <th>converse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45825.000000</td>\n",
       "      <td>45825</td>\n",
       "      <td>45796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>44465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PRESCRIPTION</td>\n",
       "      <td>clinical list changes medfusion secure electro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12077</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28645.024441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16545.373029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14296.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28668.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42965.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>57280.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID    categories  \\\n",
       "count   45825.000000         45825   \n",
       "unique           NaN             6   \n",
       "top              NaN  PRESCRIPTION   \n",
       "freq             NaN         12077   \n",
       "mean    28645.024441           NaN   \n",
       "std     16545.373029           NaN   \n",
       "min         2.000000           NaN   \n",
       "25%     14296.000000           NaN   \n",
       "50%     28668.000000           NaN   \n",
       "75%     42965.000000           NaN   \n",
       "max     57280.000000           NaN   \n",
       "\n",
       "                                                 converse  \n",
       "count                                               45796  \n",
       "unique                                              44465  \n",
       "top     clinical list changes medfusion secure electro...  \n",
       "freq                                                  133  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # #DISPLAY THE DATA TYPE OF EACH VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             int64\n",
       "categories    object\n",
       "converse      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Check the unique classes in categories column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['categories'])\n",
    "\n",
    "pd.value_counts(data['categories'])\n",
    "\n",
    "np.size(np.unique(data['categories']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # #Check the data for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             0\n",
       "categories     0\n",
       "converse      29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Categories column is of 'object' type,changing it to category data type\n",
    "data['categories'] = data['categories'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop the ID column from both train and test data\n",
    "data.drop('ID', axis=1, inplace=True)\n",
    "test.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['categories', 'converse'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the data type after changing the data type to categorical\n",
    "data.dtypes\n",
    "\n",
    "#Check the columns \n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45825,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label Encoder encodes the categorical classes as different numbers\n",
    "#Since the 'categories' column is the column to be predicted in test,set labels\n",
    "#to the differone hot encoded verson\n",
    "LabelEncoder = preprocessing.LabelEncoder()\n",
    "labels = LabelEncoder.fit_transform(data['categories'])\n",
    "y_labels= np_utils.to_categorical(labels, 6)\n",
    "set(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the data into train and validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(data.iloc[:,1], y_labels, test_size=0.3, random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting the X_train and X_validation is now converted to array from \n",
    "#dataframe, for ease of use convert them to list so that they can be used in \n",
    "#tokenizer\n",
    "\n",
    "x_train_sent=[i for i in X_train]\n",
    "\n",
    "x_validation_sent=[j for j in X_validation ]\n",
    "\n",
    "test_sent=[k for k in test.iloc[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,32057):\n",
    "    x_train_sent[i]=re.sub(\"[^a-zA-Z]\", \" \",str(x_train_sent[i]))\n",
    "    x_train_sent[i].lower()\n",
    "\n",
    "for i in range(0,13739):\n",
    "    x_validation_sent[i]=re.sub(\"[^a-zA-Z]\", \" \",str(x_validation_sent[i]))\n",
    "    x_validation_sent[i].lower()\n",
    "\n",
    "for i in range(0,11455):\n",
    "    test_sent[i]=re.sub(\"[^a-zA-Z]\", \" \",str(test_sent[i]))\n",
    "    test_sent[i].lower()\n",
    "    \n",
    "    \n",
    "complete=x_train_sent+x_validation_sent+test_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39289 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Prepare tokenizer for train and validation\n",
    "tokenizer1 = Tokenizer()\n",
    "tokenizer1.fit_on_texts(complete)\n",
    "\n",
    "vocab_Size = len(tokenizer1.word_index) + 1\n",
    "print('Found %s unique tokens.' % vocab_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510, 18711, 59, 8, 60, 38, 60, 296, 2, 1, 26, 73, 13, 18711, 59, 20, 98, 127, 22, 26, 553, 8, 171, 325, 111, 72, 2, 72, 1447, 1494, 22, 26, 438, 16, 2, 6, 37, 35, 707, 4, 15, 226, 569, 88, 3, 2713, 16, 4162, 2, 67, 1, 480, 15, 3, 1, 72, 157, 35283, 6, 140, 61, 6, 445, 1, 247, 282, 88, 32, 425, 3, 1169, 44, 178, 19, 1, 194, 195, 3, 103, 19, 15, 69, 6, 272, 1, 289, 327, 45, 10, 410, 7, 19, 88, 359, 3, 1, 86, 40, 6, 172, 1351, 1006, 41, 407, 18, 53, 10, 2590, 17, 524, 127, 101, 4, 3539, 7, 4, 88, 3, 18, 6, 37, 35284, 1, 4, 247, 36, 120, 3944, 30, 123, 193, 7, 171, 325, 111]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "#train\n",
    "sequences_train = tokenizer1.texts_to_sequences(x_train_sent)\n",
    "\n",
    "\n",
    "# integer encode the documents\n",
    "#validation\n",
    "sequences_validation = tokenizer1.texts_to_sequences(x_validation_sent)\n",
    "\n",
    "\n",
    "# integer encode the documents\n",
    "#test\n",
    "sequences_test = tokenizer1.texts_to_sequences(test_sent)\n",
    "print( sequences_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_data tensor: (32077, 700)\n",
      "Shape of validation_data tensor: (13748, 700)\n",
      "Shape of test_data tensor: (11455, 700)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 700\n",
    "\n",
    "train_pad = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "print('Shape of train_data tensor:', train_pad.shape)\n",
    "\n",
    "validation_pad = pad_sequences(sequences_validation, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "print('Shape of validation_data tensor:', validation_pad.shape)\n",
    "\n",
    "test_pad = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "print('Shape of test_data tensor:', test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32077, 700)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lstm_model\n",
    "\n",
    "\n",
    "# create the model\n",
    "\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(vocab_Size, 2, input_length=MAX_SEQUENCE_LENGTH))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(100))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 700, 32)           1257248   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 700, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 1,311,054\n",
      "Trainable params: 1,311,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32077 samples, validate on 13748 samples\n",
      "Epoch 1/4\n",
      " - 816s - loss: 1.5647 - acc: 0.2520 - val_loss: 1.5441 - val_acc: 0.2671\n",
      "Epoch 2/4\n",
      " - 725s - loss: 1.5546 - acc: 0.2514 - val_loss: 1.5441 - val_acc: 0.2671\n",
      "Epoch 3/4\n",
      " - 637s - loss: 1.5527 - acc: 0.2573 - val_loss: 1.5441 - val_acc: 0.2671\n",
      "Epoch 4/4\n",
      " - 641s - loss: 1.5514 - acc: 0.2565 - val_loss: 1.5430 - val_acc: 0.2671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e34dcaacf8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "lstm_model.fit(train_pad, y_train,validation_data=(validation_pad, y_validation),epochs=4,batch_size=64,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.202575\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = lstm_model.evaluate(train_pad, y_train, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25086784,  0.20218466,  0.00074438,  0.07854893,  0.20986401,\n",
       "         0.25779021],\n",
       "       [ 0.25086784,  0.20218463,  0.00074438,  0.07854892,  0.20986399,\n",
       "         0.25779021],\n",
       "       [ 0.25086784,  0.20218465,  0.00074438,  0.07854892,  0.20986399,\n",
       "         0.25779021],\n",
       "       ..., \n",
       "       [ 0.25086784,  0.20218465,  0.00074438,  0.07854892,  0.20986399,\n",
       "         0.25779021],\n",
       "       [ 0.25086784,  0.20218463,  0.00074438,  0.07854892,  0.20986399,\n",
       "         0.25779021],\n",
       "       [ 0.25086784,  0.20218465,  0.00074438,  0.07854892,  0.20986399,\n",
       "         0.25779021]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict on validation\n",
    "\n",
    "validation_pred = lstm_model.predict(validation_pad)\n",
    "validation_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 26.709340\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = lstm_model.evaluate(validation_pad, y_validation, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict on test\n",
    "test_pred = lstm_model.predict(test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_pred\n",
    "\n",
    "test_predictions =[]\n",
    "for i in test_pred:\n",
    "    test_predictions.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inverse_transform using labelencoder\n",
    "\n",
    "test_predictions = LabelEncoder.inverse_transform(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_file\n",
    "test = pd.read_csv(\"test.csv\",header=0)\n",
    "\n",
    "copy_test=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write to the output file\n",
    "output = {'ID':copy_test['ID'],'categories': test_predictions}\n",
    "output_df = pd.DataFrame(data=output)\n",
    "\n",
    "pd.value_counts(output['categories'])\n",
    "\n",
    "output_df.to_csv('predict2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
